{
  "hash": "247da4d601484b4896d8a0a19a0d0e5e",
  "result": {
    "markdown": "---\ntitle: \"Phase 1: Data Wrangling\"\ntitle-block-banner: true\ntoc: true\neditor: visual\nexecute: \n  freeze: true\n  warning: false\n  #echo: false\n  #message: false\n  html:\n    code-fold: True\n    code-overflow: scroll\n    code-summary: \"Show the code\"\n    code-line-numbers: true\n---\n\n\n# 1 PISA Data\n\nThe PISA Data from 2000 to 2022 are available on the [OECD website](https://www.oecd.org/pisa/data/).\n\n# 2 Getting Started\n\n| **Library**                                 | **Description**                                                                                               |\n|------------------------|-----------------------------------------------|\n| [**tidyverse**](https://www.tidyverse.org/) | A collection of core packages designed for data science, used extensively for data preparation and wrangling. |\n| [**haven**](https://haven.tidyverse.org/)   | To enable R to read and write various data formats such as SAS and SPSS.                                      |\n| [**knitr**](https://yihui.org/knitr/)       | For dynamic report generation.                                                                                |\n\n: {tbl-colwidths=\"\\[20,80\\]\"}\n\nThe following code chunk uses `p_load()` of [**pacman**](https://rpubs.com/akshaypatankar/594834) package to check if tidyverse packages are installed in the computer. If they are, the libraries will be called into R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, haven, knitr, \n               sjlabelled,\n               gt)\n```\n:::\n\n\n# 3 Reading Data into R\n\nThe next two sections cover the steps taken to read in the raw data.\n\n## 3.1 Importing sas file\n\nFrom PISA 2015 and its later cycles, SAS data sets (`.sas`) are available with all countries in the file for each respondent type.\n\nThe code chunk below imports the *2015, 2018, 2022 Student Questionnaire* dataset downloaded from OECD's PISA Database using the following functions:\n\n-   `list.files()` to identify all SAS files in the data directory and stores their paths in *filename* variable\n\n-   `for (i in 1:length(filenames))` iterates over each file identified, and:\n\n    -   `read_sas()` function of the [**haven**](https://haven.tidyverse.org/) package to import each file into the R environment,\n\n    -   `sub()` to extract parts of the file name without extension and parent directory path,\n\n    -   `assign()` assigns extracted partial file name to the data that was read,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List of all SAS files in directory\nfilenames <- list.files(path = \"data/\",\n                        pattern = \"*.sas7bdat\",\n                        full.names = T)\n\nfor (i in 1:length(filenames))\n{\n  name <- sub(\"^.*?/(.*?)(\\\\.sas7bdat)$\", \"\\\\1\", filenames[i])\n  data <- read_sas(filenames[i])\n  assign (name, data)\n}\n```\n:::\n\n\n## 3.2 Importing txt file with dictionary\n\nPISA 2012 and its earlier cycles' data are provided in 2 forms -- a fixed width (or ASCII) text format (`.txt`), and the corresponding SAS import control syntax file (`.sas`) for reading the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading the dictionary\ndict_student_2012 = SAScii::parse.SAScii(sas_ri = 'data/PISA2012_SAS_student.sas')\n\n# Creating the positions to read_fwf\nstu_qqq_2012 <- read_fwf(file = 'data/stu_qqq_2012.txt', col_positions = fwf_widths(dict_student_2012$width), progress = T)\n\n# Assigns column headers using dictionary\ncolnames(stu_qqq_2012) <- dict_student_2012$varname\n```\n:::\n\n\nEach dataset is a tibble dataframe, containing observations (rows) across variables (columns). Each observation corresponds to an entry from a student who participated in the PISA survey for students in the respective years, and the variables correspond to information from students on various aspects of their home, family, and school background.\n\n# 4 Data Wrangling\n\n\n```{mermaid}\n%%| fig-width: 8\n%%| echo: false\n\nflowchart TD\n\n    A[PISA Survey] --> A1[2022 Data Student Questionnaire] \n\n    A1 -.-> A11(Gender)\n    A1 -.-> A12(Socio-economic)\n    A1 -.-> A13(Psychological Wellbeing)\n    A1 -.-> A14(Schools)  \n\n    A1 -.-> A2   \n    A2[Combine 2012-2018]-.->A3(Longitudinal)\n\n    \n\n```\n\n\nThe data manipulation is performed in 2 parts:\n\n-   *Longitudinal data:* To conduct longitudinal comparisons of PISA scores of Singapore students across different years.\n-   *Detailed 2022 Student's Questionnaire data:* To compare the PISA scores between different groups of students based on factors such as gender, socioeconomic status (e.g., employment status of parents, immigrant status), and psychological well-being (e.g., feeling of loneliness, resilience when faced with challenges). On top of that, we aim to gain an understanding of the varying levels of importance and statistical significance of the various influences on PISA scores for different clusters of students.\n\n## 4.1 Filtering for required dataset\n\n### 4.1.1 The Longitudinal Data\n\nThe helper function below is designed to extract and process data for longitudinal analysis of student scores in Math, Science and Reading. Let's break down the function:\n\n1.  *Object*: The expected argument *object* retrieves the name of object which the survey is stored in.\n2.  `deparse(substitute(object))`: Returns the name of the object as a character string and stores this as a variable *filename*.\n3.  `filter()`: Filters the dataset to only include responses from Singapore students.\n4.  `select()`: Retains columns that starts with \"PV\" and contains either \"MATH\", \"SCIE\", or \"READ\" to extract the plausible values of scores related to the subjects of Mathematics, Science, and Reading.\n    1.  `starts_with()`: Matches the beginning of the column name with \"PV\", and\n    2.  `contains()`: Searches for columns containing three alternative subjects to be matched.\n5.  `mutate()`: Creates new columns to contain newly derived variables.\n    -   *year*: Represent the responses it pertains to, extracted from the file name using `substr()`.\n    -   *math*, *reading*, *science*: Calculates the mean plausible value for math, reading, and science scores for each student using `rowMeans()` applied across selected columns identified by \\`select()\\`\\`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong <- function(object) {\n  \n  filename <- deparse(substitute(object))\n  \n  result <- object %>% \n    filter(CNT == \"SGP\") %>% \n    select(starts_with(\"PV\") & contains(c(\"MATH\", \"READ\", \"SCIE\"))) %>% \n    mutate(year = substr(filename, 9, 12),\n           math = rowMeans(across(starts_with(\"PV\") & contains(\"MATH\")), na.rm = TRUE),\n           reading = rowMeans(across(starts_with(\"PV\") & contains(\"READ\")), na.rm = TRUE),\n           science = rowMeans(across(starts_with(\"PV\") & contains(\"SCIE\")), na.rm = TRUE),\n           ) %>% \n    select(year, math, reading, science)\n  \n  return(result)\n}\n```\n:::\n\n\nLet's get the required data using the `long` function defined and combine all the results from various years together in 1 dataset named *stu_longitudinal* using `bind_rows()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_2012_SG <- long(stu_qqq_2012)\nlong_2015_SG <- long(stu_qqq_2015)\nlong_2018_SG <- long(stu_qqq_2018)\nlong_2022_SG <- long(stu_qqq_2022)\n\nstu_longtitudinal <-\n  bind_rows(list(long_2012_SG,\n                long_2015_SG,\n                long_2018_SG,\n                long_2022_SG))\n```\n:::\n\n\nThe *.rds* file format is usually smaller than its SAS file counterpart and will therefore take up less storage space. The *.rds* file will also preserve data types and classes such as factors and dates eliminating the need to redefine data types after loading the file. For fast and space efficient data storage, files can be exported as RDS and re-imported into R using [`write_rds()`](https://readr.tidyverse.org/reference/read_rds.html) and [`read_rds()`](https://readr.tidyverse.org/reference/read_rds.html) respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(stu_longtitudinal, \"data/stu_longtitudinal.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstu_longtitudinal <- read_rds(\"data/stu_longtitudinal.rds\")\n```\n:::\n\n\nLet's take a look at the first 10 rows of our longitudinal dataset.\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-e6253ffaee40d1fd03dd\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-e6253ffaee40d1fd03dd\">{\"x\":{\"filter\":\"top\",\"vertical\":false,\"filterHTML\":\"<tr>\\n  <td><\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\" disabled=\\\"\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"381.76506\\\" data-max=\\\"697.85792\\\" data-scale=\\\"13\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"420.67058\\\" data-max=\\\"686.44676\\\" data-scale=\\\"13\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"377.13538\\\" data-max=\\\"682.6184\\\" data-scale=\\\"5\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n<\\/tr>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],[\"2012\",\"2012\",\"2012\",\"2012\",\"2012\",\"2012\",\"2012\",\"2012\",\"2012\",\"2012\"],[544.7188,438.08226,685.62862,697.8579199999999,599.24442,381.76506,634.6860800000001,480.067,656.8858,571.43636],[531.9534200000001,447.91542,657.0573000000001,686.44676,571.82778,420.67058,633.5456799999999,531.5563,637.0406400000001,592.55926],[519.33982,377.13538,632.35734,682.6184,577.90004,386.83328,628.44088,462.73778,621.2607400000001,528.29168]],\"container\":\"<table class=\\\"compact\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>year<\\/th>\\n      <th>math<\\/th>\\n      <th>reading<\\/th>\\n      <th>science<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"dom\":\"tip\",\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"year\",\"targets\":1},{\"name\":\"math\",\"targets\":2},{\"name\":\"reading\",\"targets\":3},{\"name\":\"science\",\"targets\":4}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"orderCellsTop\":true,\"lengthMenu\":[5,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n### 4.1.2 The 2022 Student's Questionnaire data\n\nAfter perusing through the [Codebook](https://webfs.oecd.org/pisa2022/CY08MSP_CODEBOOK_5thDecember23.xlsx) and [Technical Report](https://www.oecd.org/pisa/data/pisa2022technicalreport/), the team narrowed down the questions from the survey that would yield insightful results. The names of the columns are stored in a *.csv* file named *colname*.\n\nTo filter the raw dataset with the columns, we first import *colname* into R environment using [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) function of [**readr**](https://readr.tidyverse.org/) package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolname <- read_csv(\"data/colname.csv\")\n```\n:::\n\n\nThe following code chunk serves the following purpose:\n\n-   `filter()` of the [**dplyr**](https://dplyr.tidyverse.org/) package to extract Singapore responses, where *CNT = SGP*, for a more focused analysis,\n\n-   `select()` function:\n\n    -   To keep columns identified in *colname*\n    -   Retain only variables with \\<20% missing values\n\n-   `mutate()` to create 3 new variables to store the mean plausible values for each subject for each row using `rowMeans()` and `across()`.\n\n-   `starts_with()` and `contains()` helps identify the columns relating to the subject.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstu_qqq_2022_SG <- stu_qqq_2022 %>% \n  \n  # Filter each dataset for CNT = \"SGP\"\n  filter(CNT == \"SGP\") %>% \n\n  # Retains desired variables\n  select(colname$colname) %>% \n\n  # Retains variables with <20% missing values\n  select(which(colSums(is.na(.))/nrow(.) < 0.2)) %>% \n\n  # Calculates the mean of plausible values for each subject per student\n  mutate(math = rowMeans(across(starts_with(\"PV\") & contains(\"MATH\")), na.rm = TRUE),\n         reading = rowMeans(across(starts_with(\"PV\") & contains(\"READ\")), na.rm = TRUE),\n         science = rowMeans(across(starts_with(\"PV\") & contains(\"SCIE\")), na.rm = TRUE),\n         ) %>% \n  \n  # Drops Plausible Values columns\n  select(-starts_with(\"PV\"))\n```\n:::\n\n\n`stu_qqq_2022_SG` contains 6606 observations across 266 variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(stu_qqq_2022_SG, \"data/stu_qqq_2022_SG.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstu_qqq_2022_SG <- read_rds(\"data/stu_qqq_2022_SG.rds\")\n```\n:::\n\n\n## 4.2 Recoding Questionnaire Responses\n\nThere are several types of responses for the Student's Questionnaire. For a start, I will store the levels and their numerical for the Yes/No questions in a vector to be applied to all the questions using a similar scale.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyesno <- c('1' = \"Yes\", \n            '2' = \"No\")\n\nyesno_col <- starts_with(\"ST250Q\",)\n\ncount <- c('1' = \"0\", \n           '2' = \"1\",\n           '3' = \"2\",\n           '4' = \">2\")\n\ncount_col <- starts_with(\"ST251Q\")\n\ndigicount <- c('1' = \"0\",\n                  '2' = \"1 or 2\",\n                  '3' = \"3-5\",\n                  '4' = \">5\",\n                  '5' = \"I don't know\")\n\ndigicount_col <- starts_with(\"ST254Q\")\n\nbookcount <- c('1' = \"0\",\n               '2' = \"1-5\",\n               '3' = \"6-10\",\n               '4' = \">10\",\n               '5' = \"I don't know\")\n  \n  \nbookcount_col <- starts_with(\"ST256Q\")\n\ncountry <- c('1' = \"Singapore\",\n             '2' = \"Other Country\")\n\ncountry_col <- starts_with(\"ST019\")\n\n\nagreedisagree <- c('1' = \"Strongly Disagree\",\n                   '2' = \"Disagree\",\n                   '3' = \"Agree\",\n                   '4' = \"Strongly Agree\")\n\nagreedisagree_col <- starts_with(\"ST267Q\")\n```\n:::\n\n\n# Data Health\n\n## Duplicates Check\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\r\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/datatables-binding-0.31/datatables.js\"></script>\r\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\r\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\r\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\r\n<link href=\"../site_libs/nouislider-7.0.10/jquery.nouislider.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/nouislider-7.0.10/jquery.nouislider.min.js\"></script>\r\n<link href=\"../site_libs/selectize-0.12.0/selectize.bootstrap3.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/selectize-0.12.0/selectize.min.js\"></script>\r\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}