{
  "hash": "2a427cb9c39e5c80598b449b2d7c173d",
  "result": {
    "markdown": "---\ntitle: \"Phase 1: Data Wrangling\"\ntitle-block-banner: true\ntoc: true\neditor: visual\nexecute: \n  freeze: auto\n  warning: false\n  #echo: false\n  #message: false\n  html:\n    code-fold: True\n    code-overflow: scroll\n    code-summary: \"Show the code\"\n    code-line-numbers: true\n---\n\n\n# PISA Data\n\nThe PISA Data from 2000 to 2022 is available on the [OECD website](https://www.oecd.org/pisa/data/).\n\n# Getting Started\n\n| **Library**                                 | **Description**                                                                                               |\n|---------------------|---------------------------------------------------|\n| [**tidyverse**](https://www.tidyverse.org/) | A collection of core packages designed for data science, used extensively for data preparation and wrangling. |\n| [**haven**](https://haven.tidyverse.org/)   | To enable R to read and write various data formats such as SAS and SPSS.                                      |\n| [**knitr**](https://yihui.org/knitr/)       | For dynamic report generation.                                                                                |\n\n: {tbl-colwidths=\"\\[20,80\\]\"}\n\nThe following code chunk uses `p_load()` of [**pacman**](https://rpubs.com/akshaypatankar/594834) package to check if tidyverse packages are installed in the computer. If they are, the libraries will be called into R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, haven, knitr, gt)\n```\n:::\n\n\n# Reading Data into R\n\nThe next two sections cover the steps taken to read in the raw data.\n\n## Importing sas file\n\nFrom PISA 2015 and its later cycles, SAS data sets (`.sas`) are available with all countries in the file for each repsondent type.\n\nThe code chunk below imports the *2015, 2018, 2022 Student Questionnaire* dataset downloaded from OECD's PISA Database using the following functions:\n\n-   `list.files()` to identify all SAS files in the data directory and stores their paths in *filename* variable\n\n-   `for (i in 1:length(filenames))` iterates over each file identified, and:\n\n    -   `read_sas()` function of the [**haven**](https://haven.tidyverse.org/) package to import each file into the R environment,\n\n    -   `sub()` to extract parts of the file name,\n\n    -   `assign` assigns extracted partial file name to the data read\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List of all SAS files in directory\nfilenames <- list.files(path = \"data/\",\n                        pattern = \"*.sas7bdat\",\n                        full.names = T)\n\nfor (i in 1:length(filenames))\n{\n  name <- sub(\"^.*?/(.*?)(\\\\.sas7bdat)$\", \"\\\\1\", filenames[i])\n  data <- read_sas(filenames[i])\n  assign (name, data)\n}\n```\n:::\n\n\n## Importing txt file with dictionary\n\nPISA 2012 and its earlier cycles' data are provided in 2 forms -- a fixed width (or ASCII) text format (`.txt`), and the corresponding SAS import control syntax file (`.sas`) for reading the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading the dictionary\ndict_student_2012 = SAScii::parse.SAScii(sas_ri = 'data/PISA2012_SAS_student.sas')\n\n# Creating the positions to read_fwf\nstu_qqq_2012 <- read_fwf(file = 'data/stu_qqq_2012.txt', col_positions = fwf_widths(dict_student_2012$width), progress = T)\n\n# Assigns column headers using dictionary\ncolnames(stu_qqq_2012) <- dict_student_2012$varname\n```\n:::\n\n\nEach dataset is a tibble dataframe, containing observations (rows) across variables (columns). Each observation corresponds to an entry from a student who participated in the PISA survey for students in the respective years, and the variables correspond to information from students on various aspects of their home, family, and school background.\n\n# Data Wrangling\n\n\n\n\n## Filtering for required dataset\n\n*CNT* refers to the country of response, we can use this to filter for Singapore (where *CNT = SGP*) responses for our analysis. [`filter()`](https://dplyr.tidyverse.org/reference/filter.html) of the [**dplyr**](https://dplyr.tidyverse.org/) package allows us to perform this extraction of participating country.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter each dataset for CNT = \"SGP\"\n\nstu_qqq_2012_SG <- stu_qqq_2012 %>% \n  filter(CNT == \"SGP\")\n\nstu_qqq_2015_SG <- stu_qqq_2015 %>% \n  filter(CNT == \"SGP\")\n\nstu_qqq_2018_SG <- stu_qqq_2018 %>% \n  filter(CNT == \"SGP\")\n\nstu_qqq_2022_SG <- stu_qqq_2022 %>% \n  filter(CNT == \"SGP\")\n```\n:::\n\n\n\nThe function below will extract required columns for longitudinal analysis of the three main subject scores for each year. The expected argument is:\n\n-   object: name of object which the survey is stored in\n-   colnames: names of columns with partial string match\n-   year: year which the observations were related to\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter each dataset for CNT = \"SG\"\nlong <- function(object, colnames, year) {\n  result <- object %>% \n    filter(CNT == \"SGP\") %>% \n    select(grep(colnames)) %>% \n    mutate(year = str_sub(object, 9, 12))\n}\n```\n:::\n\n\nThe *.rds* file format is usually smaller than its SAS file counterpart and will therefore take up less storage space. The *.rds* file will also preserve data types and classes such as factors and dates eliminating the need to redefine data types after loading the file. For fast and space efficient data storage, files can be exported as RDS and re-imported into R using [`write_rds()`](https://readr.tidyverse.org/reference/read_rds.html) and [`read_rds()`](https://readr.tidyverse.org/reference/read_rds.html) respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(stu_qqq_2022_SG, \"data/stu_qqq_2022_SG.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#stu_SG <- read_rds(\"data/stu_SG.rds\")\n```\n:::\n\n\n# Data Health\n\n## Duplicates Check\n\nBefore moving on to the next step, let us check for duplicated records to prevent double counting of our results with the help of `group_by_all()` to detect if there are more than one instance of a row with the same details throughout all the columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#duplicate <- stu_SG %>% \n#  group_by_all() %>% \n#  filter(n()>1) %>% \n#  ungroup()\n  \n#duplicate\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}